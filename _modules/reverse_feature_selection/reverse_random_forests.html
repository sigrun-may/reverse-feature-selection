

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>reverse_feature_selection.reverse_random_forests &mdash; reverse_feature_selection  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            reverse_feature_selection
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../code-doc.html">Code Documentation</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/sigrun-may/reverse-feature-selection/blob/main/LICENSE">License</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/sigrun-may/reverse-feature-selection">GitHub Repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">reverse_feature_selection</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">reverse_feature_selection.reverse_random_forests</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for reverse_feature_selection.reverse_random_forests</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) 2024 Sigrun May,</span>
<span class="c1"># Ostfalia Hochschule f√ºr angewandte Wissenschaften</span>
<span class="c1">#</span>
<span class="c1"># This software is distributed under the terms of the MIT license</span>
<span class="c1"># which is available at https://opensource.org/licenses/MIT</span>

<span class="sd">&quot;&quot;&quot;Reverse feature selection with random forest regressors.&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">multiprocessing</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">joblib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">mannwhitneyu</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">clone</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">remove_features_correlated_to_target_feature</span><span class="p">(</span>
    <span class="n">train_df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">correlation_matrix_df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">target_feature</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">meta_data</span><span class="p">:</span> <span class="nb">dict</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Remove features from the training data that are correlated to the target feature.</span>

<span class="sd">    This function creates a mask for uncorrelated features based on the correlation threshold</span>
<span class="sd">    specified in the metadata. It then uses this mask to select the uncorrelated features from the training data.</span>

<span class="sd">    Args:</span>
<span class="sd">        train_df: The training data.</span>
<span class="sd">        correlation_matrix_df: The correlation matrix of the training data.</span>
<span class="sd">        target_feature: The name of the target feature.</span>
<span class="sd">        meta_data: The metadata related to the dataset and experiment. Must contain &quot;train_correlation_threshold&quot; to</span>
<span class="sd">            define the threshold for the absolute correlation to the target feature.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The training data including the label with only the features uncorrelated to the target feature remaining.</span>

<span class="sd">    Raises:</span>
<span class="sd">        AssertionError: If no features uncorrelated to the target feature are found.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Create a mask for uncorrelated features based on the correlation threshold</span>
    <span class="n">uncorrelated_features_mask</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">correlation_matrix_df</span><span class="p">[</span><span class="n">target_feature</span><span class="p">]</span>
        <span class="o">.</span><span class="n">abs</span><span class="p">()</span>
        <span class="o">.</span><span class="n">le</span><span class="p">(</span><span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;train_correlation_threshold&quot;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;index&quot;</span><span class="p">)</span>
        <span class="c1"># For a correlation matrix filled only with the lower half,</span>
        <span class="c1"># the first elements up to the diagonal would have to be read</span>
        <span class="c1"># with axis=&quot;index&quot; and the further elements after the diagonal</span>
        <span class="c1"># with axis=&quot;column&quot;.</span>
    <span class="p">)</span>
    <span class="c1"># Remove correlated features from the training data</span>
    <span class="n">uncorrelated_train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="n">train_df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">uncorrelated_features_mask</span><span class="p">]]</span>

    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">uncorrelated_train_df</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;No features uncorrelated to the target feature found.&quot;</span>

    <span class="c1"># insert the &#39;label&#39; as the first column if it is not already there</span>
    <span class="k">if</span> <span class="n">uncorrelated_train_df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;label&quot;</span><span class="p">:</span>
        <span class="n">uncorrelated_train_df</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">,</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">])</span>

    <span class="c1"># Return the data frame with uncorrelated features</span>
    <span class="k">return</span> <span class="n">uncorrelated_train_df</span>


<span class="k">def</span><span class="w"> </span><span class="nf">calculate_oob_errors</span><span class="p">(</span>
    <span class="n">target_feature_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">train_df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">corr_matrix_df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">meta_data</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="nb">list</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate out-of-bag (OOB) error for training data first including the label and again excluding the label.</span>

<span class="sd">    Args:</span>
<span class="sd">        target_feature_name: The name of the target feature.</span>
<span class="sd">        train_df: The training data.</span>
<span class="sd">        corr_matrix_df: The correlation matrix of the training data.</span>
<span class="sd">        meta_data: The metadata related to the dataset and experiment.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tuple containing lists of OOB scores for labeled and unlabeled training data and the number of features in</span>
<span class="sd">        the training data.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Prepare training data</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="n">target_feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

    <span class="c1"># Remove features correlated to the target feature</span>
    <span class="n">x_train</span> <span class="o">=</span> <span class="n">remove_features_correlated_to_target_feature</span><span class="p">(</span><span class="n">train_df</span><span class="p">,</span> <span class="n">corr_matrix_df</span><span class="p">,</span> <span class="n">target_feature_name</span><span class="p">,</span> <span class="n">meta_data</span><span class="p">)</span>
    <span class="n">number_of_features_in_training_data</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">oob_errors_labeled</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">oob_errors_unlabeled</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># chose 1/10 of the available CPUs for nested parallel processing</span>
    <span class="n">n_jobs</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;n_cpus&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">10</span><span class="p">))</span>

    <span class="c1"># Perform validation using different random seeds</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;random_seeds&quot;</span><span class="p">]:</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="c1"># Create a RandomForestRegressor model with specified parameters</span>
        <span class="n">clf1</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span>
            <span class="n">oob_score</span><span class="o">=</span><span class="n">mean_squared_error</span><span class="p">,</span>  <span class="c1"># Use out-of-bag error for evaluation</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Create an exact clone of the RandomForestRegressor (clf1)</span>
        <span class="c1"># https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html</span>
        <span class="n">clf2</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">clf1</span><span class="p">)</span>

        <span class="c1"># Fit the first model with training data including the label</span>
        <span class="n">clf1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">label_importance_zero</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">clf1</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mf">0.0</span><span class="p">)</span>

        <span class="c1"># If the feature importance of the label feature is zero, it means the label was not considered in the model</span>
        <span class="k">if</span> <span class="n">label_importance_zero</span><span class="p">:</span>
            <span class="n">oob_errors_unlabeled</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">return</span> <span class="n">oob_errors_labeled</span><span class="p">,</span> <span class="n">oob_errors_unlabeled</span><span class="p">,</span> <span class="n">number_of_features_in_training_data</span>

        <span class="c1"># Store the OOB score for the labeled model</span>
        <span class="n">oob_errors_labeled</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clf1</span><span class="o">.</span><span class="n">oob_score_</span><span class="p">)</span>

        <span class="c1"># Fit the second model to the unlabeled training data (excluding &#39;label&#39; column)</span>
        <span class="n">unlabeled_x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">columns</span> <span class="o">!=</span> <span class="s2">&quot;label&quot;</span><span class="p">]</span>
        <span class="n">clf2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">unlabeled_x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1"># Store the OOB score for the unlabeled model</span>
        <span class="n">oob_errors_unlabeled</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clf2</span><span class="o">.</span><span class="n">oob_score_</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">oob_errors_labeled</span><span class="p">,</span> <span class="n">oob_errors_unlabeled</span><span class="p">,</span> <span class="n">number_of_features_in_training_data</span>


<span class="k">def</span><span class="w"> </span><span class="nf">validate_and_initialize_meta_data</span><span class="p">(</span><span class="n">meta_data</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Validate and initialize the metadata dictionary.</span>

<span class="sd">    This function ensures that the metadata dictionary contains the required keys with valid values.</span>
<span class="sd">    If the metadata is not provided or is missing any required keys, default values are assigned.</span>

<span class="sd">    Args:</span>
<span class="sd">        meta_data: The metadata dictionary to validate and initialize. If None, a new dictionary</span>
<span class="sd">            with default values is created.</span>

<span class="sd">    Returns:</span>
<span class="sd">        The validated and initialized metadata dictionary.</span>

<span class="sd">    Raises:</span>
<span class="sd">        AssertionError: If any of the required keys in the metadata dictionary have invalid types or values.</span>

<span class="sd">    Default Values:</span>
<span class="sd">        - &quot;n_cpus&quot;: The number of available CPUs (`multiprocessing.cpu_count()`).</span>
<span class="sd">        - &quot;random_seeds&quot;: A list of 30 random integers between 1 and 10000.</span>
<span class="sd">        - &quot;train_correlation_threshold&quot;: A float value of 0.7, representing the absolute correlation threshold.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># initialize numpy random number generator</span>
    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>

    <span class="c1"># Set default values if meta_data is not defined</span>
    <span class="k">if</span> <span class="n">meta_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">meta_data</span> <span class="o">=</span> <span class="p">{</span>
            <span class="c1"># Use all available CPUs</span>
            <span class="s2">&quot;n_cpus&quot;</span><span class="p">:</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">(),</span>
            <span class="c1"># Generate a list of 30 random integers to initialize random forests multiple times</span>
            <span class="s2">&quot;random_seeds&quot;</span><span class="p">:</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10001</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
            <span class="c1"># Absolute correlation threshold for removing features correlated to the target feature</span>
            <span class="s2">&quot;train_correlation_threshold&quot;</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Meta data have been set to the default values of </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;1. </span><span class="si">{</span><span class="n">meta_data</span><span class="p">[</span><span class="s1">&#39;n_cpus&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> CPUs for parallel calculation </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;2. 30 random integers as seeds for random forests </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;3. 0.7 as absolute correlation threshold for removing features from the training data correlated to the &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;target feature&quot;</span>
        <span class="p">)</span>
    <span class="c1"># Ensure &quot;n_cpus&quot; is defined, otherwise set to the number of available CPUs</span>
    <span class="k">if</span> <span class="s2">&quot;n_cpus&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">meta_data</span><span class="p">:</span>
        <span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;n_cpus&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="o">.</span><span class="n">cpu_count</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of CPUs is set to </span><span class="si">{</span><span class="n">meta_data</span><span class="p">[</span><span class="s1">&#39;n_cpus&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># Ensure &quot;random_seeds&quot; is defined, otherwise generate a list of 30 random integers</span>
    <span class="k">if</span> <span class="s2">&quot;random_seeds&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">meta_data</span><span class="p">:</span>
        <span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;random_seeds&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10001</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Seeds for random forests have been set to the default of 30 random integers&quot;</span><span class="p">)</span>
    <span class="c1"># Ensure &quot;train_correlation_threshold&quot; is defined, otherwise set to 0.7</span>
    <span class="k">if</span> <span class="s2">&quot;train_correlation_threshold&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">meta_data</span><span class="p">:</span>
        <span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;train_correlation_threshold&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.7</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Absolute correlation threshold has been set to the default of 0.7&quot;</span><span class="p">)</span>

    <span class="c1"># Validate the types and values of the metadata keys</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;n_cpus&quot;</span><span class="p">],</span> <span class="nb">int</span><span class="p">),</span> <span class="s2">&quot;Number of available CPUs is not an integer.&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;random_seeds&quot;</span><span class="p">],</span> <span class="nb">list</span><span class="p">),</span> <span class="s2">&quot;Random seeds are not a list.&quot;</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
        <span class="nb">isinstance</span><span class="p">(</span><span class="n">seed_random_forest</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">seed_random_forest</span> <span class="ow">in</span> <span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;random_seeds&quot;</span><span class="p">]</span>
    <span class="p">),</span> <span class="s2">&quot;Random seeds are not integers.&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;train_correlation_threshold&quot;</span><span class="p">],</span> <span class="nb">float</span><span class="p">),</span> <span class="s2">&quot;Correlation threshold is not a float.&quot;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;train_correlation_threshold&quot;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Correlation threshold is not between 0 and 1.&quot;</span>

    <span class="k">return</span> <span class="n">meta_data</span>


<div class="viewcode-block" id="select_feature_subset">
<a class="viewcode-back" href="../../code-doc.html#reverse_feature_selection.reverse_random_forests.select_feature_subset">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">select_feature_subset</span><span class="p">(</span>
    <span class="n">data_df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">train_indices</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">label_column_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;label&quot;</span><span class="p">,</span>
    <span class="n">meta_data</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Selects a subset of features based on the mean out-of-bag (OOB) errors for random forests regressors.</span>

<span class="sd">    Calculate the mean out-of-bag (OOB) errors for random forests regressors with different random seeds</span>
<span class="sd">    for training data including the label and without the label for each feature. It then selects a subset of features</span>
<span class="sd">    based on the Mann-Whitney U test which determines whether there is a significant difference between the</span>
<span class="sd">    two error distributions. The test is configured for the hypothesis that the distribution of</span>
<span class="sd">    labeled_error_distribution is shifted to the left of the unlabeled_error_distribution.</span>
<span class="sd">    The Mann-Whitney U test is used to calculate the p-value based on the Out-of-Bag (OOB) scores of the labeled</span>
<span class="sd">    and unlabeled error distributions. The p-value is a measure of the probability that an observed difference</span>
<span class="sd">    could have occurred just by random chance. The smaller the p-value, the greater the statistical evidence</span>
<span class="sd">    to reject the null hypothesis (conclude that both error distributions differ).</span>

<span class="sd">    Args:</span>
<span class="sd">        data_df: The training data. The data must contain the label and features.</span>
<span class="sd">        train_indices: Indices for the training split.</span>
<span class="sd">            The indices are used to select the training data from the data_df DataFrame.</span>
<span class="sd">        label_column_name: The name of the label column in the training data. Default is &quot;label&quot;.</span>
<span class="sd">        meta_data: The metadata related to the dataset and experiment. If `meta_data` is `None`, default values for the</span>
<span class="sd">            required keys (`&quot;n_cpus&quot;`, `&quot;random_seeds&quot;`, and `&quot;train_correlation_threshold&quot;`) are used.</span>

<span class="sd">            1. `n_cpus`: The number of available CPUs is required as an integer and defaults to</span>
<span class="sd">               `multiprocessing.cpu_count()`.</span>
<span class="sd">            2. `random_seeds`: A list of different seeds to initalize random forests is used to generate comparable</span>
<span class="sd">               error distributions. Define list of random seeds for reproducibility. Default is generating a random</span>
<span class="sd">               list of 30 seeds (int).</span>
<span class="sd">            3. `train_correlation_threshold`: The absolute correlation threshold for removing features from the training</span>
<span class="sd">               data correlated to the target feature is a float between 0 and 1. The higher the threshold, the more</span>
<span class="sd">               features are deselected. The default value is set to `0.7` and should be adjusted if the results are</span>
<span class="sd">               not satisfactory.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A pandas DateFrame with the selected features in the &quot;feature_subset_selection&quot; column.</span>
<span class="sd">        The feature_subset_selection column contains the fraction difference based on the mean of OOB score</span>
<span class="sd">        distributions, where the p_value is smaller or equal to 0.05. Features with values greater than 0 in this column</span>
<span class="sd">        are selected.</span>

<span class="sd">        The remaining columns provide additional information:</span>

<span class="sd">        * `feature_subset_selection_median`: Contains the feature subset based on the median fraction difference.</span>
<span class="sd">        * `unlabeled_errors`: Lists the OOB scores for the unlabeled training data.</span>
<span class="sd">        * `labeled_errors`: Lists the OOB scores for the labeled training data.</span>
<span class="sd">        * `p_value`: Contains the p-values from the Mann-Whitney U test.</span>
<span class="sd">        * `fraction_mean`: Shows the fraction difference based on the mean of the distributions.</span>
<span class="sd">        * `fraction_median`: Shows the fraction difference based on the median of the distributions.</span>
<span class="sd">        * `train_features_count`: Indicates the number of uncorrelated features in the training data.</span>

<span class="sd">        The index of the DataFrame is the feature names.</span>

<span class="sd">    Raises:</span>
<span class="sd">        AssertionError: If the meta_data dictionary does not contain the required keys or if the values are not of</span>
<span class="sd">            the expected type. Also, if the training data does not contain any features or if the label column is not</span>
<span class="sd">            found in the training data.</span>
<span class="sd">        ValueError: If no features uncorrelated to the target feature are found.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="n">label_column_name</span> <span class="ow">in</span> <span class="n">data_df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Label column </span><span class="si">{</span><span class="n">label_column_name</span><span class="si">}</span><span class="s2"> not found in the training data.&quot;</span>

    <span class="k">if</span> <span class="n">label_column_name</span> <span class="o">!=</span> <span class="s2">&quot;label&quot;</span><span class="p">:</span>
        <span class="c1"># rename label column</span>
        <span class="n">data_df</span><span class="p">[</span><span class="n">label_column_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_df</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>
    <span class="k">assert</span> <span class="s2">&quot;label&quot;</span> <span class="ow">in</span> <span class="n">data_df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="s2">&quot;Label column not found in the training data.&quot;</span>

    <span class="c1"># check if feature importance calculation is possible</span>
    <span class="k">if</span> <span class="n">data_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No features found in the training data.&quot;</span><span class="p">)</span>

    <span class="n">meta_data</span> <span class="o">=</span> <span class="n">validate_and_initialize_meta_data</span><span class="p">(</span><span class="n">meta_data</span><span class="p">)</span>

    <span class="c1"># Split the data and select the training data</span>
    <span class="n">train_df</span> <span class="o">=</span> <span class="n">data_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_indices</span><span class="p">,</span> <span class="p">:]</span>

    <span class="c1"># Calculate the correlation matrix of the training data</span>
    <span class="n">correlation_matrix_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;spearman&quot;</span><span class="p">)</span>

    <span class="c1"># parallel version</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;n_cpus&quot;</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">)(</span>
        <span class="n">delayed</span><span class="p">(</span><span class="n">calculate_oob_errors</span><span class="p">)(</span><span class="n">target_feature_name</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">correlation_matrix_df</span><span class="p">,</span> <span class="n">meta_data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">target_feature_name</span> <span class="ow">in</span> <span class="n">data_df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="p">)</span>
    <span class="n">p_value_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">fraction_list_mean</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">fraction_list_median</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">calculated_seeds_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Unpack the results from the parallel processing</span>
    <span class="n">labeled_error_distribution_list</span><span class="p">,</span> <span class="n">unlabeled_error_distribution_list</span><span class="p">,</span> <span class="n">features_count_in_train_df</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="o">*</span><span class="n">out</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="c1"># Calculate the p-value and fraction differences based on the mean and median of the distributions</span>
    <span class="k">for</span> <span class="n">labeled_error_distribution</span><span class="p">,</span> <span class="n">unlabeled_error_distribution</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="n">labeled_error_distribution_list</span><span class="p">,</span> <span class="n">unlabeled_error_distribution_list</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">unlabeled_error_distribution</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">labeled_error_distribution</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">unlabeled_error_distribution</span><span class="p">)</span>
            <span class="n">calculated_seeds_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">unlabeled_error_distribution</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># the current target feature was deselected because the feature importance of the label was zero</span>
            <span class="n">p_value_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">fraction_list_mean</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">fraction_list_median</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">calculated_seeds_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labeled_error_distribution</span><span class="p">))</span>
            <span class="k">continue</span>

        <span class="c1"># calculate p-value based on the OOB scores and the mann-whitney u test</span>
        <span class="c1"># https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html</span>
        <span class="n">p_value</span> <span class="o">=</span> <span class="n">mannwhitneyu</span><span class="p">(</span><span class="n">labeled_error_distribution</span><span class="p">,</span> <span class="n">unlabeled_error_distribution</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s2">&quot;less&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pvalue</span>
        <span class="n">p_value_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p_value</span><span class="p">)</span>

        <span class="c1"># calculate the fraction difference of the two means of the distributions</span>
        <span class="n">fraction_mean_based</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">unlabeled_error_distribution</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">labeled_error_distribution</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
            <span class="n">unlabeled_error_distribution</span>
        <span class="p">)</span>
        <span class="n">fraction_list_mean</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fraction_mean_based</span><span class="p">)</span>

        <span class="c1"># calculate the fraction difference of the two medians of the distributions</span>
        <span class="n">fraction_median_based</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">unlabeled_error_distribution</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">labeled_error_distribution</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">unlabeled_error_distribution</span><span class="p">)</span>
        <span class="n">fraction_list_median</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fraction_median_based</span><span class="p">)</span>

    <span class="n">feature_subset_selection_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">feature_subset_selection_list_median</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># extract feature selection array</span>
    <span class="k">for</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">fraction_mean</span><span class="p">,</span> <span class="n">fraction_median</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="n">p_value_list</span><span class="p">,</span> <span class="n">fraction_list_mean</span><span class="p">,</span> <span class="n">fraction_list_median</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">):</span>
        <span class="c1"># check if the value of the &quot;p_value&quot; column is smaller or equal than 0.05</span>
        <span class="k">if</span> <span class="n">p_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">p_value</span> <span class="o">&lt;=</span> <span class="mf">0.05</span><span class="p">:</span>
            <span class="n">feature_subset_selection_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fraction_mean</span><span class="p">)</span>
            <span class="n">feature_subset_selection_list_median</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fraction_median</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">feature_subset_selection_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
            <span class="n">feature_subset_selection_list_median</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>

    <span class="k">assert</span> <span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">labeled_error_distribution_list</span><span class="p">)</span>
        <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">unlabeled_error_distribution_list</span><span class="p">)</span>
        <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">p_value_list</span><span class="p">)</span>
        <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">fraction_list_mean</span><span class="p">)</span>
        <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">fraction_list_median</span><span class="p">)</span>
        <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_subset_selection_list</span><span class="p">)</span>
        <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_subset_selection_list_median</span><span class="p">)</span>
        <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">calculated_seeds_list</span><span class="p">)</span>
        <span class="o">==</span> <span class="n">data_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># exclude label column</span>
    <span class="p">)</span>
    <span class="n">result_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">data_df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;feature_subset_selection&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature_subset_selection_list</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;feature_subset_selection_median&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature_subset_selection_list_median</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;unlabeled_errors&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">unlabeled_error_distribution_list</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;labeled_errors&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labeled_error_distribution_list</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;p_value&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_value_list</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;fraction_mean&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fraction_list_mean</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;fraction_median&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fraction_list_median</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;train_features_count&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_subset_selection_list</span><span class="p">),</span> <span class="n">features_count_in_train_df</span><span class="p">)</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;number_of_repeated_trainings&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">calculated_seeds_list</span>
    <span class="k">return</span> <span class="n">result_df</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Sigrun May.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>