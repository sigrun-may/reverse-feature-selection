

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>reverse_feature_selection.reverse_rf_random &mdash; reverse_feature_selection  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
      <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            reverse_feature_selection
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../code-doc.html">Code Documentation</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/sigrun-may/reverse_feature_selection/blob/main/LICENSE">License</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/sigrun-may/reverse_feature_selection">GitHub Repository</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">reverse_feature_selection</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">reverse_feature_selection.reverse_rf_random</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for reverse_feature_selection.reverse_rf_random</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) 2024 Sigrun May,</span>
<span class="c1"># Ostfalia Hochschule f√ºr angewandte Wissenschaften</span>
<span class="c1">#</span>
<span class="c1"># This software is distributed under the terms of the MIT license</span>
<span class="c1"># which is available at https://opensource.org/licenses/MIT</span>

<span class="sd">&quot;&quot;&quot;Reverse feature selection with random forest regressors.&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">math</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">joblib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">mannwhitneyu</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">clone</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">reverse_feature_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">preprocessing</span>

<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">calculate_oob_errors</span><span class="p">(</span>
    <span class="n">target_feature_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">train_df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">corr_matrix_df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">meta_data</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="nb">list</span> <span class="o">|</span> <span class="kc">None</span><span class="p">,</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate out-of-bag (OOB) error for labeled and unlabeled training data.</span>

<span class="sd">    Args:</span>
<span class="sd">        target_feature_name: The name of the target feature.</span>
<span class="sd">        train_df: The training data.</span>
<span class="sd">        corr_matrix_df: The correlation matrix of the training data.</span>
<span class="sd">        meta_data: The metadata related to the dataset and experiment.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A tuple containing lists of OOB scores for labeled and unlabeled training data.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Prepare training data</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="n">target_feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

    <span class="c1"># Remove features correlated to the target feature</span>
    <span class="n">x_train</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">remove_features_correlated_to_target_feature</span><span class="p">(</span>
        <span class="n">train_df</span><span class="p">,</span> <span class="n">corr_matrix_df</span><span class="p">,</span> <span class="n">target_feature_name</span><span class="p">,</span> <span class="n">meta_data</span>
    <span class="p">)</span>

    <span class="n">oob_errors_labeled</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">oob_errors_unlabeled</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># chose 1/10 of the available CPUs for nested parallel processing</span>
    <span class="n">n_jobs</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;n_cpus&quot;</span><span class="p">]</span> <span class="o">/</span> <span class="mi">10</span><span class="p">))</span>

    <span class="c1"># Perform validation using different random seeds</span>
    <span class="k">for</span> <span class="n">seed</span> <span class="ow">in</span> <span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;random_seeds&quot;</span><span class="p">]:</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span>
        <span class="c1"># Create a RandomForestRegressor model with specified parameters</span>
        <span class="n">clf1</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span>
            <span class="n">oob_score</span><span class="o">=</span><span class="n">mean_squared_error</span><span class="p">,</span>  <span class="c1"># Use out-of-bag error for evaluation</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Create an exact clone of the RandomForestRegressor (clf1)</span>
        <span class="c1"># https://scikit-learn.org/stable/modules/generated/sklearn.base.clone.html</span>
        <span class="n">clf2</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">clf1</span><span class="p">)</span>

        <span class="c1"># Fit the first model with training data including the label</span>
        <span class="n">clf1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">label_importance_zero</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">clf1</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mf">0.0</span><span class="p">)</span>

        <span class="c1"># If the feature importance of the label feature is zero, it means the label was not considered in the model</span>
        <span class="k">if</span> <span class="n">label_importance_zero</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Store the OOB score for the labeled model</span>
        <span class="n">oob_errors_labeled</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clf1</span><span class="o">.</span><span class="n">oob_score_</span><span class="p">)</span>

        <span class="c1"># Fit the second model to the unlabeled training data (excluding &#39;label&#39; column)</span>
        <span class="n">unlabeled_x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">columns</span> <span class="o">!=</span> <span class="s2">&quot;label&quot;</span><span class="p">]</span>
        <span class="n">clf2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">unlabeled_x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1"># Store the OOB score for the unlabeled model</span>
        <span class="n">oob_errors_unlabeled</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clf2</span><span class="o">.</span><span class="n">oob_score_</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">oob_errors_labeled</span><span class="p">,</span> <span class="n">oob_errors_unlabeled</span><span class="p">,</span> <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>


<div class="viewcode-block" id="select_feature_subset">
<a class="viewcode-back" href="../../code-doc.html#reverse_feature_selection.reverse_rf_random.select_feature_subset">[docs]</a>
<span class="k">def</span><span class="w"> </span><span class="nf">select_feature_subset</span><span class="p">(</span><span class="n">data_df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">train_indices</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">meta_data</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Selects a subset of features based on the mean out-of-bag (OOB) errors for random forest regressors.</span>

<span class="sd">    Calculate the mean out-of-bag (OOB) errors for random forest regressors with different random seeds</span>
<span class="sd">    for training data including the label and without the label for each feature. It then selects a subset of features</span>
<span class="sd">    based on the Mann-Whitney U test which determines whether there is a significant difference between the</span>
<span class="sd">    two error distributions. The test is configured for the hypothesis that the distribution of</span>
<span class="sd">    labeled_error_distribution is shifted to the left of the unlabeled_error_distribution.</span>
<span class="sd">    The Mann-Whitney U test is used to calculate the p-value based on the Out-of-Bag (OOB) scores of the labeled</span>
<span class="sd">    and unlabeled error distributions. The p-value is a measure of the probability that an observed difference</span>
<span class="sd">    could have occurred just by random chance. The smaller the p-value, the greater the statistical evidence</span>
<span class="sd">    to reject the null hypothesis (conclude that both error distributions differ).</span>

<span class="sd">    Args:</span>
<span class="sd">        data_df: The training data. The first column must contain the label and the remaining columns the features.</span>
<span class="sd">            The label column must be named &quot;label&quot;.</span>
<span class="sd">        train_indices: Indices for the training split.</span>
<span class="sd">        meta_data: The metadata related to the dataset and experiment.</span>
<span class="sd">            The required keys are: &quot;n_cpus&quot;, &quot;random_seeds&quot; and &quot;train_correlation_threshold&quot;. Number of available CPUs</span>
<span class="sd">            as integer and a list of random seeds for reproducibility of the repeated reverse random forest.</span>
<span class="sd">            The correlation threshold for removing correlated features is a float between 0 and 1. The threshold is used</span>
<span class="sd">            to remove features correlated to the target feature. The target feature is the feature for which the</span>
<span class="sd">            feature subset is selected. The higher the threshold, the more features are removed.</span>

<span class="sd">    Returns:</span>
<span class="sd">        A DataFrame containing raw data with lists of OOB scores for repeated analyzes of labeled and unlabeled data,</span>
<span class="sd">        p_values and fraction differences based on means and medians of the distributions. The feature_subset_selection</span>
<span class="sd">        column contains the fraction difference based on the mean of the distributions, where the p_value is smaller or</span>
<span class="sd">        equal to 0.05. Those features are selected for the feature subset.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="s2">&quot;n_cpus&quot;</span> <span class="ow">in</span> <span class="n">meta_data</span><span class="p">,</span> <span class="s2">&quot;Number of available CPUs not found in meta_data.&quot;</span>
    <span class="k">assert</span> <span class="s2">&quot;random_seeds&quot;</span> <span class="ow">in</span> <span class="n">meta_data</span><span class="p">,</span> <span class="s2">&quot;Random seeds not found in meta_data.&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;n_cpus&quot;</span><span class="p">],</span> <span class="nb">int</span><span class="p">),</span> <span class="s2">&quot;Number of available CPUs is not an integer.&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;random_seeds&quot;</span><span class="p">],</span> <span class="nb">list</span><span class="p">),</span> <span class="s2">&quot;Random seeds are not a list.&quot;</span>
    <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span>
        <span class="nb">isinstance</span><span class="p">(</span><span class="n">seed_random_forest</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">seed_random_forest</span> <span class="ow">in</span> <span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;random_seeds&quot;</span><span class="p">]</span>
    <span class="p">),</span> <span class="s2">&quot;Random seeds are not integers.&quot;</span>
    <span class="k">assert</span> <span class="s2">&quot;train_correlation_threshold&quot;</span> <span class="ow">in</span> <span class="n">meta_data</span><span class="p">,</span> <span class="s2">&quot;Correlation threshold not found in meta_data.&quot;</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;train_correlation_threshold&quot;</span><span class="p">],</span> <span class="nb">float</span><span class="p">),</span> <span class="s2">&quot;Correlation threshold is not a float.&quot;</span>
    <span class="k">assert</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;train_correlation_threshold&quot;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Correlation threshold is not between 0 and 1.&quot;</span>
    <span class="k">assert</span> <span class="s2">&quot;label&quot;</span> <span class="ow">in</span> <span class="n">data_df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="s2">&quot;Label column not found in the training data.&quot;</span>
    <span class="k">assert</span> <span class="n">data_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;No features found in the training data.&quot;</span>

    <span class="c1"># check if feature importance calculation is possible</span>
    <span class="k">if</span> <span class="n">data_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No features found in the training data.&quot;</span><span class="p">)</span>

    <span class="c1"># Split the training data into a training and test set</span>
    <span class="n">train_df</span> <span class="o">=</span> <span class="n">data_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_indices</span><span class="p">,</span> <span class="p">:]</span>

    <span class="c1"># Calculate the correlation matrix of the training data</span>
    <span class="n">correlation_matrix_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">corr</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s2">&quot;spearman&quot;</span><span class="p">)</span>

    <span class="c1"># parallel version</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="n">meta_data</span><span class="p">[</span><span class="s2">&quot;n_cpus&quot;</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=-</span><span class="mi">1</span><span class="p">)(</span>
        <span class="n">delayed</span><span class="p">(</span><span class="n">calculate_oob_errors</span><span class="p">)(</span><span class="n">target_feature_name</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">correlation_matrix_df</span><span class="p">,</span> <span class="n">meta_data</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">target_feature_name</span> <span class="ow">in</span> <span class="n">data_df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
    <span class="p">)</span>
    <span class="n">p_value_list</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">fraction_list_mean</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">fraction_list_median</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Unpack the results from the parallel processing</span>
    <span class="n">labeled_error_distribution_list</span><span class="p">,</span> <span class="n">unlabeled_error_distribution_list</span><span class="p">,</span> <span class="n">features_count_in_train_df</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="o">*</span><span class="n">out</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="c1"># Calculate the p-value and fraction differences based on the mean and median of the distributions</span>
    <span class="k">for</span> <span class="n">labeled_error_distribution</span><span class="p">,</span> <span class="n">unlabeled_error_distribution</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="n">labeled_error_distribution_list</span><span class="p">,</span> <span class="n">unlabeled_error_distribution_list</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">labeled_error_distribution</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">unlabeled_error_distribution</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># the current target feature was deselected because the feature importance of the label was zero</span>
            <span class="n">p_value_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">fraction_list_mean</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="n">fraction_list_median</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="c1"># calculate p-value based on the OOB scores and the mann-whitney u test</span>
        <span class="c1"># https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html</span>
        <span class="n">p_value</span> <span class="o">=</span> <span class="n">mannwhitneyu</span><span class="p">(</span><span class="n">labeled_error_distribution</span><span class="p">,</span> <span class="n">unlabeled_error_distribution</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s2">&quot;less&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">pvalue</span>
        <span class="n">p_value_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">p_value</span><span class="p">)</span>

        <span class="c1"># calculate the fraction difference of the two means of the distributions</span>
        <span class="n">fraction_mean_based</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">unlabeled_error_distribution</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">labeled_error_distribution</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
            <span class="n">unlabeled_error_distribution</span>
        <span class="p">)</span>
        <span class="n">fraction_list_mean</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fraction_mean_based</span><span class="p">)</span>

        <span class="c1"># calculate the fraction difference of the two medians of the distributions</span>
        <span class="n">fraction_median_based</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">unlabeled_error_distribution</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">labeled_error_distribution</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">unlabeled_error_distribution</span><span class="p">)</span>
        <span class="n">fraction_list_median</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fraction_median_based</span><span class="p">)</span>

    <span class="n">feature_subset_selection_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">feature_subset_selection_list_median</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># extract feature selection array</span>
    <span class="k">for</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">fraction_mean</span><span class="p">,</span> <span class="n">fraction_median</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="n">p_value_list</span><span class="p">,</span> <span class="n">fraction_list_mean</span><span class="p">,</span> <span class="n">fraction_list_median</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">):</span>
        <span class="c1"># check if the value of the &quot;p_value&quot; column is smaller or equal than 0.05</span>
        <span class="k">if</span> <span class="n">p_value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">p_value</span> <span class="o">&lt;=</span> <span class="mf">0.05</span><span class="p">:</span>
            <span class="n">feature_subset_selection_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fraction_mean</span><span class="p">)</span>
            <span class="n">feature_subset_selection_list_median</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fraction_median</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">feature_subset_selection_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
            <span class="n">feature_subset_selection_list_median</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>

    <span class="k">assert</span> <span class="p">(</span>
        <span class="nb">len</span><span class="p">(</span><span class="n">labeled_error_distribution_list</span><span class="p">)</span>
        <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">unlabeled_error_distribution_list</span><span class="p">)</span>
        <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">p_value_list</span><span class="p">)</span>
        <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">fraction_list_mean</span><span class="p">)</span>
        <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">fraction_list_median</span><span class="p">)</span>
        <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_subset_selection_list</span><span class="p">)</span>
        <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">feature_subset_selection_list_median</span><span class="p">)</span>
        <span class="o">==</span> <span class="n">data_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># exclude label column</span>
    <span class="p">)</span>
    <span class="n">result_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">data_df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;feature_subset_selection&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature_subset_selection_list</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;feature_subset_selection_median&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">feature_subset_selection_list_median</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;unlabeled_errors&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">unlabeled_error_distribution_list</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;labeled_errors&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labeled_error_distribution_list</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;p_value&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">p_value_list</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;fraction_mean&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fraction_list_mean</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;fraction_median&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fraction_list_median</span>
    <span class="n">result_df</span><span class="p">[</span><span class="s2">&quot;train_features_count&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">feature_subset_selection_list</span><span class="p">),</span> <span class="n">features_count_in_train_df</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result_df</span></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Sigrun May.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>